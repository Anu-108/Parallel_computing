{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHb_EL_3XXOn",
        "outputId": "ef8c8996-c0e4-4ae7-c564-2efbef58b947"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vectoradd.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile vectoradd.cu\n",
        "\n",
        "//using malloc\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define BLOCK_SIZE 256\n",
        "\n",
        "__global__ void vectorAdd(int *a, int *b, int *c, int n) {\n",
        "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (id < n) {\n",
        "        c[id] = a[id] + b[id];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[]) {\n",
        "    int *h_a, *h_b, *h_c;\n",
        "    int *d_a, *d_b, *d_c;\n",
        "    int n = 1024; // default size\n",
        "\n",
        "    if (argc > 1) n = atoi(argv[1]);\n",
        "    printf(\"Vector size: %d elements\\n\", n);\n",
        "\n",
        "    size_t size = n * sizeof(int);\n",
        "\n",
        "    // Timing variables\n",
        "    cudaEvent_t start, stop;\n",
        "    clock_t host_start, host_end;\n",
        "    float kernel_time = 0.0f;\n",
        "\n",
        "    // Create CUDA events\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Start host timer\n",
        "    host_start = clock();\n",
        "\n",
        "    // Host memory allocation\n",
        "    h_a = (int*)malloc(size);\n",
        "    h_b = (int*)malloc(size);\n",
        "    h_c = (int*)malloc(size);\n",
        "\n",
        "    // Initialize with random values\n",
        "    srand(time(NULL));\n",
        "    for(int i = 0; i < n; i++) {\n",
        "        h_a[i] = rand() % 100;\n",
        "        h_b[i] = rand() % 100;\n",
        "    }\n",
        "\n",
        "    // Device memory allocation\n",
        "    cudaMalloc(&d_a, size);\n",
        "    cudaMalloc(&d_b, size);\n",
        "    cudaMalloc(&d_c, size);\n",
        "\n",
        "    // Copy data to device\n",
        "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Kernel launch configuration\n",
        "    int numBlocks = (n + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "\n",
        "    // Launch kernel with timing\n",
        "    cudaEventRecord(start);\n",
        "    vectorAdd<<<numBlocks, BLOCK_SIZE>>>(d_a, d_b, d_c, n);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    // Calculate kernel time\n",
        "    cudaEventElapsedTime(&kernel_time, start, stop);\n",
        "\n",
        "    // Copy result back to host\n",
        "    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Stop host timer\n",
        "    host_end = clock();\n",
        "\n",
        "    // Verification (optional)\n",
        "    printf(\"\\nSample results (first 5 elements):\\n\");\n",
        "    for(int i = 0; i < 5; i++) {\n",
        "        printf(\"%d + %d = %d\\n\", h_a[i], h_b[i], h_c[i]);\n",
        "    }\n",
        "\n",
        "    // Print timing results\n",
        "    printf(\"\\nTiming statistics:\\n\");\n",
        "    printf(\"Kernel execution time: %.4f ms\\n\", kernel_time);\n",
        "    printf(\"Total host time: %.4f ms\\n\",\n",
        "          ((double)(host_end - host_start) / CLOCKS_PER_SEC) * 1000);\n",
        "\n",
        "    // Cleanup\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c);\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o vectoradd vectoradd.cu -lcurand -arch=sm_75\n",
        "!./vectoradd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR4DJH8IaZ58",
        "outputId": "d39d82d7-8489-4ab2-f456-3c5ce74a9c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector size: 1024 elements\n",
            "\n",
            "Sample results (first 5 elements):\n",
            "71 + 2 = 0\n",
            "19 + 57 = 0\n",
            "2 + 52 = 0\n",
            "29 + 4 = 0\n",
            "52 + 46 = 0\n",
            "\n",
            "Timing statistics:\n",
            "Kernel execution time: 0.0000 ms\n",
            "Total host time: 0.0920 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1 assign 4"
      ],
      "metadata": {
        "id": "tC2q7obebhdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sum.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define N 1024\n",
        "\n",
        "__global__ void sumKernel(int *input, int *output) {\n",
        "    int tid = threadIdx.x;\n",
        "    if (tid == 0) {\n",
        "        // Task A: Iterative Sum\n",
        "        int sum = 0;\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            sum += input[i];\n",
        "        }\n",
        "        output[0] = sum;\n",
        "    }\n",
        "    else if (tid == 1) {\n",
        "        output[1] = (N * (N - 1)) / 2;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int h_input[N], h_output[2] = {0};\n",
        "\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_input[i] = i;\n",
        "    }\n",
        "\n",
        "    int *d_input, *d_output;\n",
        "    cudaMalloc(&d_input, N * sizeof(int));\n",
        "    cudaMalloc(&d_output, 2 * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_input, h_input, N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    float milliseconds = 0;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    sumKernel<<<1, 2>>>(d_input, d_output);\n",
        "\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    cudaMemcpy(h_output, d_output, 2 * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Sum using Iteration (Thread 0): %d\\n\", h_output[0]);\n",
        "    printf(\"Sum using Formula   (Thread 1): %d\\n\", h_output[1]);\n",
        "    printf(\"GPU Kernel Execution Time: %.6f ms\\n\", milliseconds);\n",
        "\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wZaQNMpbggK",
        "outputId": "08555772-06e2-4dfc-8276-da9ed60aef38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing sum.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --gpu-architecture=sm_70 sum.cu -o sum\n",
        "!./sum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK4xLbP2leLR",
        "outputId": "53ee3119-f451-49de-ac98-180937eb1ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum using Iteration (Thread 0): 0\n",
            "Sum using Formula   (Thread 1): 0\n",
            "GPU Kernel Execution Time: 0.000000 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2 assign 4"
      ],
      "metadata": {
        "id": "Xa_WYQEYbrpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile merge.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define BLOCK_SIZE 256\n",
        "\n",
        "__device__ void merge(int *arr, int l, int m, int r, int *temp) {\n",
        "    int i = l, j = m + 1, k = 0;\n",
        "\n",
        "    while (i <= m && j <= r) {\n",
        "        if (arr[i] <= arr[j]) {\n",
        "            temp[k++] = arr[i++];\n",
        "        } else {\n",
        "            temp[k++] = arr[j++];\n",
        "        }\n",
        "    }\n",
        "\n",
        "    while (i <= m) temp[k++] = arr[i++];\n",
        "    while (j <= r) temp[k++] = arr[j++];\n",
        "\n",
        "    for (i = l, k = 0; i <= r; i++, k++) {\n",
        "        arr[i] = temp[k];\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void mergeSortKernel(int *arr, int n, int step) {\n",
        "    extern __shared__ int temp[];\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int l = idx * step * 2;\n",
        "    int m = l + step - 1;\n",
        "    int r = min(l + step * 2 - 1, n - 1);\n",
        "\n",
        "    if (l < n && m < n && r < n) {\n",
        "        merge(arr, l, m, r, temp);\n",
        "    }\n",
        "}\n",
        "\n",
        "void cudaMergeSort(int *h_arr, int n) {\n",
        "    int *d_arr;\n",
        "    size_t size = n * sizeof(int);\n",
        "\n",
        "    // Allocate device memory\n",
        "    cudaMalloc(&d_arr, size);\n",
        "    cudaMemcpy(d_arr, h_arr, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Kernel configuration\n",
        "    dim3 threadsPerBlock(BLOCK_SIZE);\n",
        "    dim3 blocksPerGrid((n + threadsPerBlock.x - 1) / threadsPerBlock.x);\n",
        "\n",
        "    // Perform iterative merge sort\n",
        "    for (int step = 1; step < n; step *= 2) {\n",
        "        mergeSortKernel<<<blocksPerGrid, threadsPerBlock, BLOCK_SIZE * sizeof(int)>>>(d_arr, n, step);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "\n",
        "    // Copy sorted array back to host\n",
        "    cudaMemcpy(h_arr, d_arr, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_arr);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 1000;\n",
        "    int *arr = (int*)malloc(n * sizeof(int));\n",
        "\n",
        "    // Initialize array with random values\n",
        "    srand(time(NULL));\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        arr[i] = rand() % 1000;\n",
        "    }\n",
        "\n",
        "    printf(\"Unsorted Array:\\n\");\n",
        "    for (int i = 0; i < 10; i++) { // Print first 10 elements\n",
        "        printf(\"%d \", arr[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    // Time CUDA Merge Sort\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    cudaMergeSort(arr, n);\n",
        "    cudaEventRecord(stop);\n",
        "\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float milliseconds;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    printf(\"Sorted Array:\\n\");\n",
        "    for (int i = 0; i < 10; i++) { // Print first 10 elements\n",
        "        printf(\"%d \", arr[i]);\n",
        "    }\n",
        "\n",
        "    printf(\"\\nCUDA Merge Sort Time: %.4f ms\\n\", milliseconds);\n",
        "\n",
        "    free(arr);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9sVW-DubumQ",
        "outputId": "f4f3f9c7-d4e4-4bae-913f-70d27840827c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing merge.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o merge merge.cu -lcurand -arch=sm_75\n",
        "!./merge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJypFH9GcF9P",
        "outputId": "257805aa-60fc-4629-c6b3-0d4ba8571b83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsorted Array:\n",
            "997 771 589 278 528 560 53 219 100 249 \n",
            "Sorted Array:\n",
            "997 771 589 278 528 560 53 219 100 249 \n",
            "CUDA Merge Sort Time: 0.0000 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment 5"
      ],
      "metadata": {
        "id": "6c7v5EqsmJcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_add.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define N 1024  // Size of vectors\n",
        "\n",
        "// Use unified memory accessible from both host and device\n",
        "__managed__ float A[N], B[N], C[N];\n",
        "\n",
        "// CUDA kernel for vector addition\n",
        "__global__ void vectorAdd() {\n",
        "    int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (i < N)\n",
        "        C[i] = A[i] + B[i];\n",
        "}\n",
        "\n",
        "// Error checker utility\n",
        "void check(cudaError_t err, const char *msg) {\n",
        "    if (err != cudaSuccess) {\n",
        "        printf(\"CUDA error %s: %s\\n\", msg, cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Initialize input arrays\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        A[i] = i * 1.0f;\n",
        "        B[i] = i * 2.0f;\n",
        "    }\n",
        "\n",
        "    // CUDA event setup for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    float time_ms = 0;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    // Launch the kernel\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>();\n",
        "    check(cudaGetLastError(), \"Kernel launch\");\n",
        "\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time_ms, start, stop);\n",
        "\n",
        "    // Print first 5 results\n",
        "    printf(\"C = [\");\n",
        "    for (int i = 0; i < 5; ++i)\n",
        "        printf(\"%.1f \", C[i]);\n",
        "    printf(\"...]\\n\");\n",
        "\n",
        "    // Device properties\n",
        "    cudaDeviceProp prop;\n",
        "    cudaGetDeviceProperties(&prop, 0);\n",
        "\n",
        "    float memClock = prop.memoryClockRate * 1e3;   // Hz\n",
        "    float busWidth = prop.memoryBusWidth;          // bits\n",
        "    float theoreticalBW = 2 * memClock * busWidth / 8 / 1e9;  // GB/s\n",
        "    printf(\"Theoretical Bandwidth: %.2f GB/s\\n\", theoreticalBW);\n",
        "\n",
        "    // Actual bandwidth\n",
        "    float totalBytes = 3 * N * sizeof(float); // A & B read, C written\n",
        "    float measuredBW = totalBytes / (time_ms / 1000.0f) / 1e9; // GB/s\n",
        "    printf(\"Measured Bandwidth: %.2f GB/s\\n\", measuredBW);\n",
        "    printf(\"Execution Time: %.4f ms\\n\", time_ms);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "r5sDdtXlmL4p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d538871-d2ca-49a5-ce0e-711f79b7f557"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --gpu-architecture=sm_70 vector_add.cu -o vector_add\n",
        "!./vector_add"
      ],
      "metadata": {
        "id": "vjDAxQ-95THK"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}